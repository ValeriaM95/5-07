{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "from keras import models\n",
    "from keras.datasets import cifar10\n",
    "import matplotlib.pylab as plt\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.models import Sequential, Input, Model\n",
    "from keras.layers import Dense, Dropout, Flatten, GlobalAveragePooling2D\n",
    "import tensorflow as tf\n",
    "from keras.applications import vgg16\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_data, train_labels), (test_data, test_labels) = cifar10.load_data()\n",
    "train_data_2, val_data, train_labels_2, val_labels = train_test_split(train_data, train_labels, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 32, 32, 64)        1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 32, 32, 64)        36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 16, 16, 64)        0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 16, 16, 128)       73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 16, 16, 128)       147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 8, 8, 128)         0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 8, 8, 256)         295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 8, 8, 256)         590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 8, 8, 256)         590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 4, 4, 256)         0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 4, 4, 512)         1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 4, 4, 512)         2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 4, 4, 512)         2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 2, 2, 512)         0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 2, 2, 512)         2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 2, 2, 512)         2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 2, 2, 512)         2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 1, 1, 512)         0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 0\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vgg_conv = vgg16.VGG16(weights='imagenet', include_top=False, input_shape= (32, 32, 3))\n",
    "\n",
    "for layer in vgg_conv.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "vgg_conv.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.engine.input_layer.InputLayer object at 0x0000028DD682F8E0> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x0000028DFE9AFA30> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x0000028D89344040> False\n",
      "<keras.layers.pooling.MaxPooling2D object at 0x0000028D893453C0> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x0000028D89344640> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x0000028D89346E90> False\n",
      "<keras.layers.pooling.MaxPooling2D object at 0x0000028D89347820> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x0000028D893457B0> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x0000028D89347A30> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x0000028D953689D0> False\n",
      "<keras.layers.pooling.MaxPooling2D object at 0x0000028D9536AF80> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x0000028D9536AB00> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x0000028D9536A4A0> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x0000028D9537CC40> False\n",
      "<keras.layers.pooling.MaxPooling2D object at 0x0000028D9537DF30> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x0000028D9536AC80> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x0000028D9537C430> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x0000028D9537FE20> False\n",
      "<keras.layers.pooling.MaxPooling2D object at 0x0000028D95394CD0> False\n"
     ]
    }
   ],
   "source": [
    "for layer in vgg_conv.layers:\n",
    "    print(layer, layer.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6],\n",
       "       [9],\n",
       "       [9],\n",
       "       ...,\n",
       "       [9],\n",
       "       [1],\n",
       "       [1]], dtype=uint8)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " vgg16 (Functional)          (None, 1, 1, 512)         14714688  \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 512)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,719,818\n",
      "Trainable params: 5,130\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(vgg_conv)\n",
    "model.add(Flatten(input_shape=(None, 64, 64, 3)))\n",
    "model.add(layers.Dense(10, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1250/1250 [==============================] - 100s 78ms/step - loss: 1.9205 - accuracy: 0.5330\n",
      "Epoch 2/20\n",
      "1250/1250 [==============================] - 93s 75ms/step - loss: 1.8700 - accuracy: 0.5391\n",
      "Epoch 3/20\n",
      "1250/1250 [==============================] - 95s 76ms/step - loss: 1.8952 - accuracy: 0.5310\n",
      "Epoch 4/20\n",
      "1250/1250 [==============================] - 100s 80ms/step - loss: 1.8778 - accuracy: 0.5321\n",
      "Epoch 5/20\n",
      "1250/1250 [==============================] - 105s 84ms/step - loss: 1.8790 - accuracy: 0.5374\n",
      "Epoch 6/20\n",
      "1250/1250 [==============================] - 98s 79ms/step - loss: 1.8935 - accuracy: 0.5344\n",
      "Epoch 7/20\n",
      "1250/1250 [==============================] - 105s 84ms/step - loss: 1.8732 - accuracy: 0.5350\n",
      "Epoch 8/20\n",
      "1250/1250 [==============================] - 99s 80ms/step - loss: 1.9009 - accuracy: 0.5350\n",
      "Epoch 9/20\n",
      "1250/1250 [==============================] - 98s 78ms/step - loss: 1.8833 - accuracy: 0.5360\n",
      "Epoch 10/20\n",
      "1250/1250 [==============================] - 99s 79ms/step - loss: 1.8970 - accuracy: 0.5335\n",
      "Epoch 11/20\n",
      "1250/1250 [==============================] - 104s 83ms/step - loss: 1.8927 - accuracy: 0.5360\n",
      "Epoch 12/20\n",
      "1250/1250 [==============================] - 102s 81ms/step - loss: 1.8784 - accuracy: 0.5347\n",
      "Epoch 13/20\n",
      "1250/1250 [==============================] - 110s 88ms/step - loss: 1.8784 - accuracy: 0.5352\n",
      "Epoch 14/20\n",
      "1250/1250 [==============================] - 105s 84ms/step - loss: 1.8827 - accuracy: 0.5373\n",
      "Epoch 15/20\n",
      "1250/1250 [==============================] - 102s 82ms/step - loss: 1.8825 - accuracy: 0.5337\n",
      "Epoch 16/20\n",
      "1250/1250 [==============================] - 115s 92ms/step - loss: 1.8760 - accuracy: 0.5367\n",
      "Epoch 17/20\n",
      "1250/1250 [==============================] - 163s 130ms/step - loss: 1.8864 - accuracy: 0.5352\n",
      "Epoch 18/20\n",
      "1250/1250 [==============================] - 172s 138ms/step - loss: 1.8998 - accuracy: 0.5331\n",
      "Epoch 19/20\n",
      "  93/1250 [=>............................] - ETA: 2:48 - loss: 1.7777 - accuracy: 0.5457"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=['accuracy'])\n",
    "history = model.fit(train_data_2, train_labels_2, epochs=20, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "313/313 [==============================] - 26s 82ms/step - loss: 5.8392 - accuracy: 0.3931\n",
      "Epoch 2/10\n",
      "313/313 [==============================] - 26s 82ms/step - loss: 1.4671 - accuracy: 0.5463\n",
      "Epoch 3/10\n",
      "313/313 [==============================] - 26s 83ms/step - loss: 1.0704 - accuracy: 0.6427\n",
      "Epoch 4/10\n",
      "313/313 [==============================] - 26s 83ms/step - loss: 0.8605 - accuracy: 0.7008\n",
      "Epoch 5/10\n",
      "313/313 [==============================] - 26s 82ms/step - loss: 0.7588 - accuracy: 0.7372\n",
      "Epoch 6/10\n",
      "313/313 [==============================] - 26s 82ms/step - loss: 0.6510 - accuracy: 0.7710\n",
      "Epoch 7/10\n",
      "313/313 [==============================] - 26s 83ms/step - loss: 0.6024 - accuracy: 0.7838\n",
      "Epoch 8/10\n",
      "313/313 [==============================] - 26s 84ms/step - loss: 0.5538 - accuracy: 0.8036\n",
      "Epoch 9/10\n",
      "313/313 [==============================] - 26s 84ms/step - loss: 0.5293 - accuracy: 0.8108\n",
      "Epoch 10/10\n",
      "313/313 [==============================] - 26s 83ms/step - loss: 0.5106 - accuracy: 0.8248\n"
     ]
    }
   ],
   "source": [
    "model_3 = Sequential()\n",
    "model_3.add(vgg_conv)\n",
    "model_3.add(Flatten(input_shape=(None, 64, 64, 3)))\n",
    "model_3.add(Dense(512, activation=\"relu\"))\n",
    "model_3.add(Dropout(0.25))\n",
    "model_3.add(Dense(10, activation='softmax'))\n",
    "model_3.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=['accuracy'])\n",
    "history = model_3.fit(val_data, val_labels, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "313/313 [==============================] - 29s 91ms/step - loss: 5.6022 - accuracy: 0.4096\n",
      "Epoch 2/60\n",
      "313/313 [==============================] - 26s 84ms/step - loss: 1.4980 - accuracy: 0.5402\n",
      "Epoch 3/60\n",
      "313/313 [==============================] - 22s 70ms/step - loss: 1.0887 - accuracy: 0.6342\n",
      "Epoch 4/60\n",
      "313/313 [==============================] - 22s 69ms/step - loss: 0.8844 - accuracy: 0.6993\n",
      "Epoch 5/60\n",
      "313/313 [==============================] - 22s 71ms/step - loss: 0.7589 - accuracy: 0.7321\n",
      "Epoch 6/60\n",
      "313/313 [==============================] - 24s 76ms/step - loss: 0.6681 - accuracy: 0.7687\n",
      "Epoch 7/60\n",
      "313/313 [==============================] - 24s 77ms/step - loss: 0.6233 - accuracy: 0.7847\n",
      "Epoch 8/60\n",
      "313/313 [==============================] - 22s 71ms/step - loss: 0.5806 - accuracy: 0.7977\n",
      "Epoch 9/60\n",
      "313/313 [==============================] - 22s 71ms/step - loss: 0.5431 - accuracy: 0.8112\n",
      "Epoch 10/60\n",
      "313/313 [==============================] - 22s 71ms/step - loss: 0.5055 - accuracy: 0.8227\n",
      "Epoch 11/60\n",
      "313/313 [==============================] - 24s 77ms/step - loss: 0.5129 - accuracy: 0.8267\n",
      "Epoch 12/60\n",
      "313/313 [==============================] - 25s 80ms/step - loss: 0.4701 - accuracy: 0.8366\n",
      "Epoch 13/60\n",
      "313/313 [==============================] - 24s 76ms/step - loss: 0.4191 - accuracy: 0.8610\n",
      "Epoch 14/60\n",
      "313/313 [==============================] - 24s 76ms/step - loss: 0.4156 - accuracy: 0.8617\n",
      "Epoch 15/60\n",
      "313/313 [==============================] - 25s 81ms/step - loss: 0.4085 - accuracy: 0.8664\n",
      "Epoch 16/60\n",
      "313/313 [==============================] - 26s 84ms/step - loss: 0.4156 - accuracy: 0.8645\n",
      "Epoch 17/60\n",
      "313/313 [==============================] - 26s 84ms/step - loss: 0.4087 - accuracy: 0.8749\n",
      "Epoch 18/60\n",
      "313/313 [==============================] - 27s 85ms/step - loss: 0.3631 - accuracy: 0.8817\n",
      "Epoch 19/60\n",
      "313/313 [==============================] - 27s 85ms/step - loss: 0.3686 - accuracy: 0.8797\n",
      "Epoch 20/60\n",
      "313/313 [==============================] - 27s 86ms/step - loss: 0.3289 - accuracy: 0.8916\n",
      "Epoch 21/60\n",
      "313/313 [==============================] - 27s 85ms/step - loss: 0.3314 - accuracy: 0.8954\n",
      "Epoch 22/60\n",
      "313/313 [==============================] - 26s 83ms/step - loss: 0.3037 - accuracy: 0.9008\n",
      "Epoch 23/60\n",
      "313/313 [==============================] - 27s 85ms/step - loss: 0.2865 - accuracy: 0.9099\n",
      "Epoch 24/60\n",
      "313/313 [==============================] - 26s 83ms/step - loss: 0.2909 - accuracy: 0.9094\n",
      "Epoch 25/60\n",
      "313/313 [==============================] - 26s 83ms/step - loss: 0.2779 - accuracy: 0.9154\n",
      "Epoch 26/60\n",
      "313/313 [==============================] - 26s 82ms/step - loss: 0.3078 - accuracy: 0.9055\n",
      "Epoch 27/60\n",
      "313/313 [==============================] - 26s 82ms/step - loss: 0.2857 - accuracy: 0.9170\n",
      "Epoch 28/60\n",
      "313/313 [==============================] - 26s 83ms/step - loss: 0.3051 - accuracy: 0.9148\n",
      "Epoch 29/60\n",
      "313/313 [==============================] - 26s 82ms/step - loss: 0.2827 - accuracy: 0.9137\n",
      "Epoch 30/60\n",
      "313/313 [==============================] - 26s 82ms/step - loss: 0.2617 - accuracy: 0.9220\n",
      "Epoch 31/60\n",
      "313/313 [==============================] - 26s 83ms/step - loss: 0.2563 - accuracy: 0.9210\n",
      "Epoch 32/60\n",
      "313/313 [==============================] - 26s 83ms/step - loss: 0.2278 - accuracy: 0.9304\n",
      "Epoch 33/60\n",
      "313/313 [==============================] - 26s 83ms/step - loss: 0.2274 - accuracy: 0.9276\n",
      "Epoch 34/60\n",
      "313/313 [==============================] - 26s 84ms/step - loss: 0.2262 - accuracy: 0.9334\n",
      "Epoch 35/60\n",
      "313/313 [==============================] - 26s 83ms/step - loss: 0.2451 - accuracy: 0.9279\n",
      "Epoch 36/60\n",
      "313/313 [==============================] - 27s 88ms/step - loss: 0.2366 - accuracy: 0.9311\n",
      "Epoch 37/60\n",
      "313/313 [==============================] - 26s 82ms/step - loss: 0.2801 - accuracy: 0.9234\n",
      "Epoch 38/60\n",
      "313/313 [==============================] - 26s 83ms/step - loss: 0.2345 - accuracy: 0.9292\n",
      "Epoch 39/60\n",
      "313/313 [==============================] - 26s 82ms/step - loss: 0.2342 - accuracy: 0.9340\n",
      "Epoch 40/60\n",
      "313/313 [==============================] - 26s 82ms/step - loss: 0.2406 - accuracy: 0.9339\n",
      "Epoch 41/60\n",
      "313/313 [==============================] - 26s 82ms/step - loss: 0.2482 - accuracy: 0.9305\n",
      "Epoch 42/60\n",
      "313/313 [==============================] - 26s 82ms/step - loss: 0.2088 - accuracy: 0.9406\n",
      "Epoch 43/60\n",
      "313/313 [==============================] - 26s 82ms/step - loss: 0.2062 - accuracy: 0.9424\n",
      "Epoch 44/60\n",
      "313/313 [==============================] - 26s 83ms/step - loss: 0.2386 - accuracy: 0.9382\n",
      "Epoch 45/60\n",
      "313/313 [==============================] - 26s 83ms/step - loss: 0.2024 - accuracy: 0.9438\n",
      "Epoch 46/60\n",
      "313/313 [==============================] - 26s 83ms/step - loss: 0.2075 - accuracy: 0.9411\n",
      "Epoch 47/60\n",
      "313/313 [==============================] - 26s 83ms/step - loss: 0.1998 - accuracy: 0.9428\n",
      "Epoch 48/60\n",
      "313/313 [==============================] - 26s 83ms/step - loss: 0.2292 - accuracy: 0.9397\n",
      "Epoch 49/60\n",
      "313/313 [==============================] - 26s 83ms/step - loss: 0.2502 - accuracy: 0.9390\n",
      "Epoch 50/60\n",
      "313/313 [==============================] - 26s 83ms/step - loss: 0.2238 - accuracy: 0.9421\n",
      "Epoch 51/60\n",
      "313/313 [==============================] - 27s 85ms/step - loss: 0.1875 - accuracy: 0.9478\n",
      "Epoch 52/60\n",
      "313/313 [==============================] - 26s 83ms/step - loss: 0.1879 - accuracy: 0.9463\n",
      "Epoch 53/60\n",
      "313/313 [==============================] - 26s 82ms/step - loss: 0.1516 - accuracy: 0.9562\n",
      "Epoch 54/60\n",
      "313/313 [==============================] - 26s 82ms/step - loss: 0.1886 - accuracy: 0.9487\n",
      "Epoch 55/60\n",
      "313/313 [==============================] - 26s 82ms/step - loss: 0.1848 - accuracy: 0.9524\n",
      "Epoch 56/60\n",
      "313/313 [==============================] - 26s 84ms/step - loss: 0.2084 - accuracy: 0.9462\n",
      "Epoch 57/60\n",
      "313/313 [==============================] - 26s 83ms/step - loss: 0.1950 - accuracy: 0.9517\n",
      "Epoch 58/60\n",
      "313/313 [==============================] - 26s 82ms/step - loss: 0.2015 - accuracy: 0.9528\n",
      "Epoch 59/60\n",
      "313/313 [==============================] - 26s 83ms/step - loss: 0.2012 - accuracy: 0.9489\n",
      "Epoch 60/60\n",
      "313/313 [==============================] - 26s 82ms/step - loss: 0.1753 - accuracy: 0.9515\n"
     ]
    }
   ],
   "source": [
    "model_5 = Sequential()\n",
    "model_5.add(vgg_conv)\n",
    "model_5.add(Flatten(input_shape=(None, 64, 64, 3)))\n",
    "model_5.add(Dense(512, activation=\"relu\"))\n",
    "model_5.add(Dropout(0.25))\n",
    "model_5.add(Dense(10, activation='softmax'))\n",
    "model_5.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=['accuracy'])\n",
    "history = model_5.fit(val_data, val_labels, epochs=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 28s 88ms/step - loss: 5.6045 - accuracy: 0.5600\n",
      "test_acc: 0.5600000023841858\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model_5.evaluate(test_data, test_labels)\n",
    "print('test_acc:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 25s 79ms/step - loss: 2.0412 - accuracy: 0.5439\n",
      "test_acc: 0.5439000129699707\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model_3.evaluate(test_data, test_labels)\n",
    "print('test_acc:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation = tf.keras.Sequential([\n",
    "layers.RandomFlip(\"horizontal\", input_shape=(32, 32,3)),\n",
    "tf.keras.layers.RandomRotation(0.1,fill_mode='reflect',interpolation='bilinear',seed=None,fill_value=0.0),\n",
    "tf.keras.layers.RandomZoom(0.1,fill_mode='reflect',interpolation='bilinear',seed=None,fill_value=0.0),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "313/313 [==============================] - 29s 89ms/step - loss: 16.6153 - accuracy: 0.2512\n",
      "Epoch 2/100\n",
      "313/313 [==============================] - 27s 87ms/step - loss: 7.6858 - accuracy: 0.3545\n",
      "Epoch 3/100\n",
      "313/313 [==============================] - 28s 89ms/step - loss: 4.8214 - accuracy: 0.3913\n",
      "Epoch 4/100\n",
      "313/313 [==============================] - 30s 96ms/step - loss: 3.5053 - accuracy: 0.3974\n",
      "Epoch 5/100\n",
      "313/313 [==============================] - 30s 95ms/step - loss: 2.8081 - accuracy: 0.4105\n",
      "Epoch 6/100\n",
      "313/313 [==============================] - 30s 95ms/step - loss: 2.6085 - accuracy: 0.4070\n",
      "Epoch 7/100\n",
      "313/313 [==============================] - 31s 98ms/step - loss: 2.4847 - accuracy: 0.4004\n",
      "Epoch 8/100\n",
      "313/313 [==============================] - 30s 97ms/step - loss: 2.4424 - accuracy: 0.4046\n",
      "Epoch 9/100\n",
      "313/313 [==============================] - 30s 97ms/step - loss: 2.4254 - accuracy: 0.3988\n",
      "Epoch 10/100\n",
      "313/313 [==============================] - 30s 96ms/step - loss: 2.4427 - accuracy: 0.4040\n",
      "Epoch 11/100\n",
      "313/313 [==============================] - 30s 97ms/step - loss: 2.4499 - accuracy: 0.4087\n",
      "Epoch 12/100\n",
      "313/313 [==============================] - 30s 95ms/step - loss: 2.4241 - accuracy: 0.4059\n",
      "Epoch 13/100\n",
      "313/313 [==============================] - 30s 95ms/step - loss: 2.4495 - accuracy: 0.4091\n",
      "Epoch 14/100\n",
      "313/313 [==============================] - 30s 95ms/step - loss: 2.5253 - accuracy: 0.3983\n",
      "Epoch 15/100\n",
      "313/313 [==============================] - 30s 96ms/step - loss: 2.4685 - accuracy: 0.4028\n",
      "Epoch 16/100\n",
      "313/313 [==============================] - 30s 95ms/step - loss: 2.4416 - accuracy: 0.3981\n",
      "Epoch 17/100\n",
      "313/313 [==============================] - 30s 95ms/step - loss: 2.4524 - accuracy: 0.4040\n",
      "Epoch 18/100\n",
      "313/313 [==============================] - 27s 88ms/step - loss: 2.4099 - accuracy: 0.4053\n",
      "Epoch 19/100\n",
      "313/313 [==============================] - 28s 89ms/step - loss: 2.4446 - accuracy: 0.4052\n",
      "Epoch 20/100\n",
      "313/313 [==============================] - 28s 90ms/step - loss: 2.4329 - accuracy: 0.4103\n",
      "Epoch 21/100\n",
      "313/313 [==============================] - 30s 96ms/step - loss: 2.4694 - accuracy: 0.3999\n",
      "Epoch 22/100\n",
      "313/313 [==============================] - 30s 97ms/step - loss: 2.4589 - accuracy: 0.4036\n",
      "Epoch 23/100\n",
      "313/313 [==============================] - 30s 97ms/step - loss: 2.4613 - accuracy: 0.3920\n",
      "Epoch 24/100\n",
      "313/313 [==============================] - 30s 95ms/step - loss: 2.4519 - accuracy: 0.4017\n",
      "Epoch 25/100\n",
      "313/313 [==============================] - 31s 99ms/step - loss: 2.4583 - accuracy: 0.4016\n",
      "Epoch 26/100\n",
      "313/313 [==============================] - 30s 96ms/step - loss: 2.4038 - accuracy: 0.4081\n",
      "Epoch 27/100\n",
      "313/313 [==============================] - 30s 96ms/step - loss: 2.4682 - accuracy: 0.4012\n",
      "Epoch 28/100\n",
      "313/313 [==============================] - 30s 95ms/step - loss: 2.4466 - accuracy: 0.3982\n",
      "Epoch 29/100\n",
      "313/313 [==============================] - 33s 107ms/step - loss: 2.4461 - accuracy: 0.3944\n",
      "Epoch 30/100\n",
      "313/313 [==============================] - 30s 96ms/step - loss: 2.4650 - accuracy: 0.4052\n",
      "Epoch 31/100\n",
      "313/313 [==============================] - 30s 95ms/step - loss: 2.4735 - accuracy: 0.3995\n",
      "Epoch 32/100\n",
      "313/313 [==============================] - 30s 95ms/step - loss: 2.4396 - accuracy: 0.4028\n",
      "Epoch 33/100\n",
      "313/313 [==============================] - 29s 93ms/step - loss: 2.4821 - accuracy: 0.4008\n",
      "Epoch 34/100\n",
      "313/313 [==============================] - 29s 92ms/step - loss: 2.4273 - accuracy: 0.4089\n",
      "Epoch 35/100\n",
      "313/313 [==============================] - 28s 89ms/step - loss: 2.5297 - accuracy: 0.3888\n",
      "Epoch 36/100\n",
      "313/313 [==============================] - 28s 89ms/step - loss: 2.4713 - accuracy: 0.4041\n",
      "Epoch 37/100\n",
      "313/313 [==============================] - 29s 94ms/step - loss: 2.4239 - accuracy: 0.4043\n",
      "Epoch 38/100\n",
      "313/313 [==============================] - 28s 88ms/step - loss: 2.4230 - accuracy: 0.4075\n",
      "Epoch 39/100\n",
      "313/313 [==============================] - 30s 95ms/step - loss: 2.4213 - accuracy: 0.4000\n",
      "Epoch 40/100\n",
      "313/313 [==============================] - 30s 94ms/step - loss: 2.4455 - accuracy: 0.4011\n",
      "Epoch 41/100\n",
      "313/313 [==============================] - 30s 95ms/step - loss: 2.4457 - accuracy: 0.4004\n",
      "Epoch 42/100\n",
      "313/313 [==============================] - 28s 91ms/step - loss: 2.5001 - accuracy: 0.3940\n",
      "Epoch 43/100\n",
      "313/313 [==============================] - 30s 95ms/step - loss: 2.4801 - accuracy: 0.3940\n",
      "Epoch 44/100\n",
      "313/313 [==============================] - 30s 94ms/step - loss: 2.4853 - accuracy: 0.3983\n",
      "Epoch 45/100\n",
      "313/313 [==============================] - 29s 92ms/step - loss: 2.4525 - accuracy: 0.3997\n",
      "Epoch 46/100\n",
      "313/313 [==============================] - 30s 94ms/step - loss: 2.4286 - accuracy: 0.4006\n",
      "Epoch 47/100\n",
      "313/313 [==============================] - 28s 90ms/step - loss: 2.4436 - accuracy: 0.3997\n",
      "Epoch 48/100\n",
      "313/313 [==============================] - 29s 93ms/step - loss: 2.4577 - accuracy: 0.3880\n",
      "Epoch 49/100\n",
      "313/313 [==============================] - 31s 98ms/step - loss: 2.4495 - accuracy: 0.4060\n",
      "Epoch 50/100\n",
      "313/313 [==============================] - 29s 93ms/step - loss: 2.4628 - accuracy: 0.4090\n",
      "Epoch 51/100\n",
      "313/313 [==============================] - 29s 93ms/step - loss: 2.4417 - accuracy: 0.4025\n",
      "Epoch 52/100\n",
      "313/313 [==============================] - 29s 93ms/step - loss: 2.4600 - accuracy: 0.4072\n",
      "Epoch 53/100\n",
      "313/313 [==============================] - 30s 95ms/step - loss: 2.4276 - accuracy: 0.4070\n",
      "Epoch 54/100\n",
      "313/313 [==============================] - 30s 95ms/step - loss: 2.4579 - accuracy: 0.4034\n",
      "Epoch 55/100\n",
      "313/313 [==============================] - 29s 94ms/step - loss: 2.4671 - accuracy: 0.4020\n",
      "Epoch 56/100\n",
      "313/313 [==============================] - 29s 92ms/step - loss: 2.4583 - accuracy: 0.3979\n",
      "Epoch 57/100\n",
      "313/313 [==============================] - 28s 88ms/step - loss: 2.4304 - accuracy: 0.4031\n",
      "Epoch 58/100\n",
      "313/313 [==============================] - 28s 88ms/step - loss: 2.4502 - accuracy: 0.4009\n",
      "Epoch 59/100\n",
      "313/313 [==============================] - 28s 88ms/step - loss: 2.4487 - accuracy: 0.4055\n",
      "Epoch 60/100\n",
      "313/313 [==============================] - 28s 88ms/step - loss: 2.4360 - accuracy: 0.4014\n",
      "Epoch 61/100\n",
      "313/313 [==============================] - 28s 89ms/step - loss: 2.4499 - accuracy: 0.4036\n",
      "Epoch 62/100\n",
      "313/313 [==============================] - 28s 89ms/step - loss: 2.4295 - accuracy: 0.4091\n",
      "Epoch 63/100\n",
      "313/313 [==============================] - 27s 88ms/step - loss: 2.4663 - accuracy: 0.4084\n",
      "Epoch 64/100\n",
      "313/313 [==============================] - 28s 88ms/step - loss: 2.4947 - accuracy: 0.3911\n",
      "Epoch 65/100\n",
      "313/313 [==============================] - 30s 95ms/step - loss: 2.4382 - accuracy: 0.3978\n",
      "Epoch 66/100\n",
      "313/313 [==============================] - 32s 104ms/step - loss: 2.4110 - accuracy: 0.4107\n",
      "Epoch 67/100\n",
      "313/313 [==============================] - 35s 113ms/step - loss: 2.4520 - accuracy: 0.4106\n",
      "Epoch 68/100\n",
      "313/313 [==============================] - 40s 127ms/step - loss: 2.4583 - accuracy: 0.3989\n",
      "Epoch 69/100\n",
      "313/313 [==============================] - 36s 116ms/step - loss: 2.4347 - accuracy: 0.4072\n",
      "Epoch 70/100\n",
      "313/313 [==============================] - 31s 100ms/step - loss: 2.4126 - accuracy: 0.4074\n",
      "Epoch 71/100\n",
      "313/313 [==============================] - 31s 99ms/step - loss: 2.4689 - accuracy: 0.3977\n",
      "Epoch 72/100\n",
      "313/313 [==============================] - 31s 100ms/step - loss: 2.4720 - accuracy: 0.4087\n",
      "Epoch 73/100\n",
      "313/313 [==============================] - 32s 101ms/step - loss: 2.4840 - accuracy: 0.3955\n",
      "Epoch 74/100\n",
      "313/313 [==============================] - 32s 101ms/step - loss: 2.4568 - accuracy: 0.4048\n",
      "Epoch 75/100\n",
      "313/313 [==============================] - 32s 102ms/step - loss: 2.4427 - accuracy: 0.4043\n",
      "Epoch 76/100\n",
      "313/313 [==============================] - 34s 110ms/step - loss: 2.4455 - accuracy: 0.4142\n",
      "Epoch 77/100\n",
      "313/313 [==============================] - 34s 110ms/step - loss: 2.4633 - accuracy: 0.4026\n",
      "Epoch 78/100\n",
      "313/313 [==============================] - 34s 109ms/step - loss: 2.4504 - accuracy: 0.4023\n",
      "Epoch 79/100\n",
      "313/313 [==============================] - 34s 110ms/step - loss: 2.4268 - accuracy: 0.4027\n",
      "Epoch 80/100\n",
      "313/313 [==============================] - 34s 108ms/step - loss: 2.4502 - accuracy: 0.4020\n",
      "Epoch 81/100\n",
      "313/313 [==============================] - 35s 111ms/step - loss: 2.4245 - accuracy: 0.4054\n",
      "Epoch 82/100\n",
      "313/313 [==============================] - 29s 94ms/step - loss: 2.4085 - accuracy: 0.4142\n",
      "Epoch 83/100\n",
      "313/313 [==============================] - 29s 92ms/step - loss: 2.4173 - accuracy: 0.4003\n",
      "Epoch 84/100\n",
      "313/313 [==============================] - 29s 92ms/step - loss: 2.4999 - accuracy: 0.4030\n",
      "Epoch 85/100\n",
      "313/313 [==============================] - 29s 92ms/step - loss: 2.4726 - accuracy: 0.3921\n",
      "Epoch 86/100\n",
      "313/313 [==============================] - 29s 92ms/step - loss: 2.4957 - accuracy: 0.3894\n",
      "Epoch 87/100\n",
      "313/313 [==============================] - 29s 92ms/step - loss: 2.4532 - accuracy: 0.4074\n",
      "Epoch 88/100\n",
      "313/313 [==============================] - 29s 92ms/step - loss: 2.4241 - accuracy: 0.4050\n",
      "Epoch 89/100\n",
      "313/313 [==============================] - 30s 95ms/step - loss: 2.4453 - accuracy: 0.4043\n",
      "Epoch 90/100\n",
      "313/313 [==============================] - 31s 98ms/step - loss: 2.5295 - accuracy: 0.3954\n",
      "Epoch 91/100\n",
      "313/313 [==============================] - 31s 99ms/step - loss: 2.4811 - accuracy: 0.4005\n",
      "Epoch 92/100\n",
      "313/313 [==============================] - 33s 105ms/step - loss: 2.4398 - accuracy: 0.4029\n",
      "Epoch 93/100\n",
      "313/313 [==============================] - 31s 100ms/step - loss: 2.4681 - accuracy: 0.4022\n",
      "Epoch 94/100\n",
      "313/313 [==============================] - 33s 104ms/step - loss: 2.4080 - accuracy: 0.4156\n",
      "Epoch 95/100\n",
      "313/313 [==============================] - 31s 99ms/step - loss: 2.4645 - accuracy: 0.4008\n",
      "Epoch 96/100\n",
      "313/313 [==============================] - 30s 97ms/step - loss: 2.4361 - accuracy: 0.4052\n",
      "Epoch 97/100\n",
      "313/313 [==============================] - 31s 98ms/step - loss: 2.4738 - accuracy: 0.4072\n",
      "Epoch 98/100\n",
      "313/313 [==============================] - 31s 100ms/step - loss: 2.4120 - accuracy: 0.4114\n",
      "Epoch 99/100\n",
      "313/313 [==============================] - 30s 96ms/step - loss: 2.4365 - accuracy: 0.4029\n",
      "Epoch 100/100\n",
      "313/313 [==============================] - 34s 108ms/step - loss: 2.4617 - accuracy: 0.3981\n"
     ]
    }
   ],
   "source": [
    "model_6 = Sequential([\n",
    "  data_augmentation,\n",
    "  vgg_conv,\n",
    "  layers.Flatten(input_shape=(None, 64, 64, 3)),\n",
    "  layers.Dropout(0.25),\n",
    "  layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model_6.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=['accuracy'])\n",
    "history_1 = model_6.fit(val_data, val_labels, epochs=100) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def myprint(s):\n",
    "    with open('modelsummary.txt','a') as f:\n",
    "        print(s, file=f)\n",
    "model.summary(print_fn=myprint)\n",
    "model_5.summary(print_fn=myprint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(test_data, test_labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
